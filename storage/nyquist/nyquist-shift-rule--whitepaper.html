<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<!-- 2024-03-06 Wed 16:19 -->
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>"Shift Rule for Gradient Determination in Parameterised Quantum Evolutions" — Whitepaper</title>
<meta name="author" content="Dirk Oliver Theis, University of Tartu, Estonia" />
<meta name="generator" content="Org Mode" />
<style>
  #content { max-width: 60em; margin: auto; }
  .title  { text-align: center;
             margin-bottom: .2em; }
  .subtitle { text-align: center;
              font-size: medium;
              font-weight: bold;
              margin-top:0; }
  .todo   { font-family: monospace; color: red; }
  .done   { font-family: monospace; color: green; }
  .priority { font-family: monospace; color: orange; }
  .tag    { background-color: #eee; font-family: monospace;
            padding: 2px; font-size: 80%; font-weight: normal; }
  .timestamp { color: #bebebe; }
  .timestamp-kwd { color: #5f9ea0; }
  .org-right  { margin-left: auto; margin-right: 0px;  text-align: right; }
  .org-left   { margin-left: 0px;  margin-right: auto; text-align: left; }
  .org-center { margin-left: auto; margin-right: auto; text-align: center; }
  .underline { text-decoration: underline; }
  #postamble p, #preamble p { font-size: 90%; margin: .2em; }
  p.verse { margin-left: 3%; }
  pre {
    border: 1px solid #e6e6e6;
    border-radius: 3px;
    background-color: #f2f2f2;
    padding: 8pt;
    font-family: monospace;
    overflow: auto;
    margin: 1.2em;
  }
  pre.src {
    position: relative;
    overflow: auto;
  }
  pre.src:before {
    display: none;
    position: absolute;
    top: -8px;
    right: 12px;
    padding: 3px;
    color: #555;
    background-color: #f2f2f299;
  }
  pre.src:hover:before { display: inline; margin-top: 14px;}
  /* Languages per Org manual */
  pre.src-asymptote:before { content: 'Asymptote'; }
  pre.src-awk:before { content: 'Awk'; }
  pre.src-authinfo::before { content: 'Authinfo'; }
  pre.src-C:before { content: 'C'; }
  /* pre.src-C++ doesn't work in CSS */
  pre.src-clojure:before { content: 'Clojure'; }
  pre.src-css:before { content: 'CSS'; }
  pre.src-D:before { content: 'D'; }
  pre.src-ditaa:before { content: 'ditaa'; }
  pre.src-dot:before { content: 'Graphviz'; }
  pre.src-calc:before { content: 'Emacs Calc'; }
  pre.src-emacs-lisp:before { content: 'Emacs Lisp'; }
  pre.src-fortran:before { content: 'Fortran'; }
  pre.src-gnuplot:before { content: 'gnuplot'; }
  pre.src-haskell:before { content: 'Haskell'; }
  pre.src-hledger:before { content: 'hledger'; }
  pre.src-java:before { content: 'Java'; }
  pre.src-js:before { content: 'Javascript'; }
  pre.src-latex:before { content: 'LaTeX'; }
  pre.src-ledger:before { content: 'Ledger'; }
  pre.src-lisp:before { content: 'Lisp'; }
  pre.src-lilypond:before { content: 'Lilypond'; }
  pre.src-lua:before { content: 'Lua'; }
  pre.src-matlab:before { content: 'MATLAB'; }
  pre.src-mscgen:before { content: 'Mscgen'; }
  pre.src-ocaml:before { content: 'Objective Caml'; }
  pre.src-octave:before { content: 'Octave'; }
  pre.src-org:before { content: 'Org mode'; }
  pre.src-oz:before { content: 'OZ'; }
  pre.src-plantuml:before { content: 'Plantuml'; }
  pre.src-processing:before { content: 'Processing.js'; }
  pre.src-python:before { content: 'Python'; }
  pre.src-R:before { content: 'R'; }
  pre.src-ruby:before { content: 'Ruby'; }
  pre.src-sass:before { content: 'Sass'; }
  pre.src-scheme:before { content: 'Scheme'; }
  pre.src-screen:before { content: 'Gnu Screen'; }
  pre.src-sed:before { content: 'Sed'; }
  pre.src-sh:before { content: 'shell'; }
  pre.src-sql:before { content: 'SQL'; }
  pre.src-sqlite:before { content: 'SQLite'; }
  /* additional languages in org.el's org-babel-load-languages alist */
  pre.src-forth:before { content: 'Forth'; }
  pre.src-io:before { content: 'IO'; }
  pre.src-J:before { content: 'J'; }
  pre.src-makefile:before { content: 'Makefile'; }
  pre.src-maxima:before { content: 'Maxima'; }
  pre.src-perl:before { content: 'Perl'; }
  pre.src-picolisp:before { content: 'Pico Lisp'; }
  pre.src-scala:before { content: 'Scala'; }
  pre.src-shell:before { content: 'Shell Script'; }
  pre.src-ebnf2ps:before { content: 'ebfn2ps'; }
  /* additional language identifiers per "defun org-babel-execute"
       in ob-*.el */
  pre.src-cpp:before  { content: 'C++'; }
  pre.src-abc:before  { content: 'ABC'; }
  pre.src-coq:before  { content: 'Coq'; }
  pre.src-groovy:before  { content: 'Groovy'; }
  /* additional language identifiers from org-babel-shell-names in
     ob-shell.el: ob-shell is the only babel language using a lambda to put
     the execution function name together. */
  pre.src-bash:before  { content: 'bash'; }
  pre.src-csh:before  { content: 'csh'; }
  pre.src-ash:before  { content: 'ash'; }
  pre.src-dash:before  { content: 'dash'; }
  pre.src-ksh:before  { content: 'ksh'; }
  pre.src-mksh:before  { content: 'mksh'; }
  pre.src-posh:before  { content: 'posh'; }
  /* Additional Emacs modes also supported by the LaTeX listings package */
  pre.src-ada:before { content: 'Ada'; }
  pre.src-asm:before { content: 'Assembler'; }
  pre.src-caml:before { content: 'Caml'; }
  pre.src-delphi:before { content: 'Delphi'; }
  pre.src-html:before { content: 'HTML'; }
  pre.src-idl:before { content: 'IDL'; }
  pre.src-mercury:before { content: 'Mercury'; }
  pre.src-metapost:before { content: 'MetaPost'; }
  pre.src-modula-2:before { content: 'Modula-2'; }
  pre.src-pascal:before { content: 'Pascal'; }
  pre.src-ps:before { content: 'PostScript'; }
  pre.src-prolog:before { content: 'Prolog'; }
  pre.src-simula:before { content: 'Simula'; }
  pre.src-tcl:before { content: 'tcl'; }
  pre.src-tex:before { content: 'TeX'; }
  pre.src-plain-tex:before { content: 'Plain TeX'; }
  pre.src-verilog:before { content: 'Verilog'; }
  pre.src-vhdl:before { content: 'VHDL'; }
  pre.src-xml:before { content: 'XML'; }
  pre.src-nxml:before { content: 'XML'; }
  /* add a generic configuration mode; LaTeX export needs an additional
     (add-to-list 'org-latex-listings-langs '(conf " ")) in .emacs */
  pre.src-conf:before { content: 'Configuration File'; }

  table { border-collapse:collapse; }
  caption.t-above { caption-side: top; }
  caption.t-bottom { caption-side: bottom; }
  td, th { vertical-align:top;  }
  th.org-right  { text-align: center;  }
  th.org-left   { text-align: center;   }
  th.org-center { text-align: center; }
  td.org-right  { text-align: right;  }
  td.org-left   { text-align: left;   }
  td.org-center { text-align: center; }
  dt { font-weight: bold; }
  .footpara { display: inline; }
  .footdef  { margin-bottom: 1em; }
  .figure { padding: 1em; }
  .figure p { text-align: center; }
  .equation-container {
    display: table;
    text-align: center;
    width: 100%;
  }
  .equation {
    vertical-align: middle;
  }
  .equation-label {
    display: table-cell;
    text-align: right;
    vertical-align: middle;
  }
  .inlinetask {
    padding: 10px;
    border: 2px solid gray;
    margin: 10px;
    background: #ffffcc;
  }
  #org-div-home-and-up
   { text-align: right; font-size: 70%; white-space: nowrap; }
  textarea { overflow-x: auto; }
  .linenr { font-size: smaller }
  .code-highlighted { background-color: #ffff00; }
  .org-info-js_info-navigation { border-style: none; }
  #org-info-js_console-label
    { font-size: 10px; font-weight: bold; white-space: nowrap; }
  .org-info-js_search-highlight
    { background-color: #ffff00; color: #000000; font-weight: bold; }
  .org-svg { }
</style>
</head>
<body>
<div id="content" class="content">
<h1 class="title">"Shift Rule for Gradient Determination in Parameterised Quantum Evolutions" — Whitepaper</h1>
<div id="table-of-contents" role="doc-toc">
<h2>Table of Contents</h2>
<div id="text-table-of-contents" role="doc-toc">
<ul>
<li><a href="#org43ce273">1. Introduction</a></li>
<li><a href="#orge7b307a">2. Background</a>
<ul>
<li><a href="#org8e3e281">2.1. Gradients of parameterized quantum evolutions &#x2014; why?</a>
<ul>
<li><a href="#org9128238">2.1.1. Quantum Machine Learning</a></li>
<li><a href="#org99afe52">2.1.2. Combinatorial Optimization</a></li>
<li><a href="#orgfbd5a86">2.1.3. Probably not applicable: Quantum chemistry</a></li>
</ul>
</li>
<li><a href="#orgf24fcd7">2.2. Gradients of parameterized quantum evolutions &#x2014; how?</a>
<ul>
<li><a href="#org22e2021">2.2.1. Symmetric Difference Quotient (SDQ)</a></li>
<li><a href="#orgd57f4b5">2.2.2. Shift rules</a></li>
<li><a href="#org53da42e">2.2.3. Banchi-Crooks' method</a></li>
<li><a href="#orgbbc3136">2.2.4. Simultaneous Perturbation Stochastic Approximation (SPSA)</a></li>
<li><a href="#orgf926028">2.2.5. Conclusion</a></li>
</ul>
</li>
<li><a href="#orgc5be573">2.3. Analog quantum computers (aka quantum simulators)</a>
<ul>
<li><a href="#org819630d">2.3.1. Rydberg atom arrays and the Rydberg Blockade                                  </a></li>
<li><a href="#org86ac3f7">2.3.2. Other analog simulators</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#org924f9b2">3. <span class="todo TODO">TODO</span> How is my invention better than the other methods?</a></li>
<li><a href="#orgcab9aae">4. Bibliography</a></li>
</ul>
</div>
</div>

<div id="outline-container-org43ce273" class="outline-2">
<h2 id="org43ce273"><span class="section-number-2">1.</span> Introduction</h2>
<div class="outline-text-2" id="text-1">
<p>
Most of the currently dominant proposals for useful near-term (i.e., pre-fault-tolerant) quantum computing make
use of quantum evolutions that depend on <i>parameters</i>, which need to be <i>trained</i> (i.e., optimized to minimize a
loss or error function) in order for the quantum evolution to give the desired result.  This approach is
referred to as <i>variational</i> quantum computing.
</p>

<p>
For example, in the context of IBM's recent (12/2023) update of their quantum computing roadmap, IBM showcased a
number of examples for what they call "quantum utility": Situations in which the use of a quantum computer
resulted in a if not commercial but at least scientific benefit.  Their examples either directly prepare quantum
states that are of scientific interest, or they use variational approaches.
</p>

<p>
The invention (<a href="#citeproc_bib_item_6">Theis 2022</a>) that is discussed in this text pertains to making variational approaches
on <i>analog quantum computers</i> (aka "quantum simulators") more efficient, by speeding up the computations of
<i>gradients</i>, which are used to train the parameters.
</p>

<p>
We first discuss where and how the "Nyquist Shift Rule" method in the invention would be used and what the
state-of-the-art methods are; then we give results comparing the Nyquist shift rule to the state-of-the-art in
numerical simulations.
</p>
</div>
</div>


<div id="outline-container-orge7b307a" class="outline-2">
<h2 id="orge7b307a"><span class="section-number-2">2.</span> Background</h2>
<div class="outline-text-2" id="text-2">
<p>
With a view towards the applicability of the invention, we firstly by discussing the types of commercial
use-cases of quantum computing in which gradients are important.  Secondly, we go through the state-of-the-art
methods.  Finally, we discuss the analog quantum computers, as the hardware domain of the invention.
</p>
</div>

<div id="outline-container-org8e3e281" class="outline-3">
<h3 id="org8e3e281"><span class="section-number-3">2.1.</span> Gradients of parameterized quantum evolutions &#x2014; why?</h3>
<div class="outline-text-3" id="text-2-1">
</div>
<div id="outline-container-org9128238" class="outline-4">
<h4 id="org9128238"><span class="section-number-4">2.1.1.</span> Quantum Machine Learning</h4>
<div class="outline-text-4" id="text-2-1-1">
<p>
In the classical world, training a neural network amounts to optimizing the parameters it comprises in such a
way that a loss function is minimized.  In quantum machine learning, parameterized quantum processes take the
role of the classical neural network &#x2014; indeed, these parameterized quantum processes are themselves
often called quantum neural networks.
</p>

<p>
<div style="color:gray;">
</p>
<blockquote>
<p>
The training of the parameters is not different between the quantum and classical worlds in two ways: (1)
There is (currently?) no <i>backpropagation</i> algorithm for quantum neural networks, leading to a linear
dependence of the efficiency of the training on the number of parameters (<a href="#citeproc_bib_item_1">Abbas et al. 2023</a>).
(2) Quantum measurements yield an additional source of randomness in the gradient estimates next to the
pseudo-randomness introduced by iterating over the training data.
</p>

<p>
Notably, in quantum machine learning, already for feeding input data into the parameterized quantum process
does it make sense to use parameters (<a href="#citeproc_bib_item_4">Gil Vidal and Theis 2020</a>).
</p>
</blockquote>
<p>
</div>
</p>

<p>
There is a wealth of parameterized quantum processes models that are showing promise for quantum machine
learning.  Some of them are tailored to analog quantum computers &#x2014; making our invention applicable.
</p>
</div>
</div>

<div id="outline-container-org99afe52" class="outline-4">
<h4 id="org99afe52"><span class="section-number-4">2.1.2.</span> Combinatorial Optimization</h4>
<div class="outline-text-4" id="text-2-1-2">
<p>
The most promising proposals to solving combinatorial optimization problems on noisy quantum computers encode
the cost-function to be minimized in the form of a cost Hamiltonian: The low-energy eigenstates of the
Hamiltonian correspond to low-cost solutions of the combinatorial optimization problem.  After preparing the
system in an initial state, an iterative version of adiabatic evolution is employed: In every step, for a
certain time, the system is subject to evolution that is a weighted sum of the cost Hamiltonian and the
initial-state Hamiltonian.  Typically, the weights in the sum are considered as parameters that are trained.
For that training, gradients are typically used.
</p>

<p>
Combinatorial optimization problems which require constraints (i.e., almost all) are more difficult to map
onto a Hamiltonian.  Luckily though, in analog quantum computing, sometimes QAOA-approaches can be combined
with "natural" constraints that are included in the system Hamiltonian; see the discussion about the <a href="#org2827d1d">2.3.1</a> below &#x2014; this is where our method can speed up gradient computations.
</p>
</div>
</div>

<div id="outline-container-orgfbd5a86" class="outline-4">
<h4 id="orgfbd5a86"><span class="section-number-4">2.1.3.</span> Probably not applicable: Quantum chemistry</h4>
<div class="outline-text-4" id="text-2-1-3">
<p>
The third large type of use-cases for parameterized quantum evolutions is quantum-computer chemistry, based,
for example, on Variational Quantum Eigensolver techniques.  While our method is in principle applicable
there, the difficulties that arise from the large number of terms in the Hamiltonians dominate, so that
gradient speed-ups have too small an effect.
</p>
</div>
</div>
</div>

<div id="outline-container-orgf24fcd7" class="outline-3">
<h3 id="orgf24fcd7"><span class="section-number-3">2.2.</span> Gradients of parameterized quantum evolutions &#x2014; how?</h3>
<div class="outline-text-3" id="text-2-2">
<p>
<div style="color:gray;">
</p>
<blockquote>
<p>
The most efficient way to train the parameters in parameterized quantum evolutions is Stochastic Gradient
Descent (SGD) and variants.  There, a current vector of parameters is maintained.  In every iteration, a random
estimate of the gradient is produced, and the parameter vector is updated by subtracting a multiple of the
gradient estimate.
</p>

<p>
The performance (number of iterations to achieve a near-optimal parameter setting) of SGD-variants depends
critically on two properties of the gradient estimator: Its <b>variance</b> and its <b>bias</b>.
</p>
</blockquote>
<p>
</div>
</p>

<p>
In the applications to near-term quantum computing outlined above, the loss function and its gradient are
estimated by repeatedly running the quantum evolution and then measuring.  The term <i>shot</i> is used to for a
single run of the quantum evolution with final measurement.  When considering the efficiency of noisy quantum
computations, the <i>number of shots</i> is the most important quantity, as each individual shot takes only a
negligible amount of time.
</p>

<p>
The fundamental randomness of quantum mechanical measurements leads to a variance in the gradient estimation.
The magnitude of that variance depends on what method is chosen for the gradient estimation.  The same holds
for the bias: Different methods for estimating gradients have differ with regards to whether a bias is present
and how large it is.
</p>

<p>
How are gradients of parameterized quantum evolutions obtained using state of the art methods?
</p>
</div>

<div id="outline-container-org22e2021" class="outline-4">
<h4 id="org22e2021"><span class="section-number-4">2.2.1.</span> Symmetric Difference Quotient (SDQ)</h4>
<div class="outline-text-4" id="text-2-2-1">
<p>
<div style="color:gray;">
</p>
<blockquote>
<p>
This simple method known from basic numerical analysis has a bias of ≈𝜖², where 𝜖 <i>&gt; 0</i> is limited only by the
precision with which the function can be evaluated.
</p>

<p>
In the quantum setting, it works as follows: For each of the parameters in turn, SDQ runs the quantum
evolution twice, with parameter settings 𝜽ⱼ → 𝜽ⱼ ±𝜖, where 𝑗 is the index of the current parameter.  The
estimate for the derivative 𝚍/𝚍𝜽ⱼ is the arithmetic mean of two measurements, scaled by a factor of 1/𝜖.  In
the case of usual Pauli-measurements, the variance is ≈ 1/𝜖².
</p>
</blockquote>
<p>
</div>
</p>

<p>
SDQ method for estimating derivatives has the property that the bias can be arbitrarily reduced &#x2014; but any
reduction in bias is paid for by an increase in variance of equal magnitude.
</p>
</div>
</div>

<div id="outline-container-orgd57f4b5" class="outline-4">
<h4 id="orgd57f4b5"><span class="section-number-4">2.2.2.</span> Shift rules</h4>
<div class="outline-text-4" id="text-2-2-2">
<p>
<div style="color:gray;">
</p>
<blockquote>
<p>
Shift rules methods work similarly to SDQ: For each parameter in turn, the derivative 𝚍/𝚍𝜽ⱼ is
estimated by updating only 𝜽ⱼ.
</p>
</blockquote>
<p>
</div>
</p>

<p>
In contrast to SDQ, shift rules (<a href="#citeproc_bib_item_8">Wierichs et al. 2021</a>) generally can lead to unbiased
estimators while at the same achieving the minimum possible variance that any unbiased estimator for the
derivative must have (<a href="#citeproc_bib_item_5">Theis 2021</a>).
</p>
</div>
</div>

<div id="outline-container-org53da42e" class="outline-4">
<h4 id="org53da42e"><span class="section-number-4">2.2.3.</span> Banchi-Crooks' method</h4>
<div class="outline-text-4" id="text-2-2-3">
<p>
Banchi and Crooks have proposed a method that they call a "stochastic approximate shift rule"
(<a href="#citeproc_bib_item_3">Banchi and Crooks 2021</a>).  The word "approximate" refers to the presence of a bias.
</p>

<p>
The advantage of their method is the following: While the standard parameter shift rules of the <a href="#orgd57f4b5">previous
section</a> work only in cases of standard quantum evolutions of the form 𝑒ⁱᶿᴬ &#x2014; which are typically found in
digital quantum computers &#x2014; Banchi &amp; Crooks' method can work with quantum evolutions that are typically
found in analog quantum computers (see <a href="#orgc5be573">2.3</a> below).
</p>

<p>
However, breaking with conventional terminology, their method requires modifications of the quantum evolution
beyond just modifying parameter values.  This results in the quantum evolutions taking longer, which means
that there is more time for quantum error to affect the outcome.  For the digital quantum computers of this
decade, this is a notable drawback.
</p>
</div>
</div>

<div id="outline-container-orgbbc3136" class="outline-4">
<h4 id="orgbbc3136"><span class="section-number-4">2.2.4.</span> Simultaneous Perturbation Stochastic Approximation (SPSA)</h4>
<div class="outline-text-4" id="text-2-2-4">
<p>
Both the vanilla SDQ and shift rules methods have the disadvantage that they need to be applied to each
parameter separately.  This means that the variance of the whole gradient vector will be proportional to the
number of parameters.  Hence, a good estimate of the gradient requires a number of shots that scales at least
linearly with the number of parameters.
</p>

<p>
SPSA is being discussed as a method that can give an estimate of the whole gradient vector with only a few
shots (e.g., two shots).
</p>

<p>
However, it was recently pointed out (Appendix A.2.3 in <a href="#citeproc_bib_item_1">Abbas et al. 2023</a>) that the SPSA
gradient estimator has a variance that is proportional to the number of parameters &#x2014; so SPSA offers no
advantage in reducing the number of shots in Stochastic Gradient Descent.
</p>
</div>
</div>

<div id="outline-container-orgf926028" class="outline-4">
<h4 id="orgf926028"><span class="section-number-4">2.2.5.</span> Conclusion</h4>
<div class="outline-text-4" id="text-2-2-5">
<p>
Due to low variance and absence of bias, shift rules are the gold standard for derivative computations.  But
with the exception of Banchi-Crooks' method, shift rules don't work for some of the typical parameterized
quantum evolutions on analog quantum computers.
</p>

<p>
The method described in the patent application is a parameter shift rule that targets the same type of quantum
evolutions as Banchi-Crooks' method, but it does away with the disadvantage of having to modify the quantum
evolution beyond changing parameter values.
</p>

<p>
Moreover, numerical simulations (<a href="#citeproc_bib_item_7">Theis 2023</a>, source code is available) have shown that the
method invented at the University of Tartu has smaller bias than Banchi-Crooks' method &#x2014; while quantum
hardware constraints and variance stay the same.  (Indeed, the method is in principle unbiased, biases only
result from limitations in the quantum hardware.)
</p>
</div>
</div>
</div>

<div id="outline-container-orgc5be573" class="outline-3">
<h3 id="orgc5be573"><span class="section-number-3">2.3.</span> Analog quantum computers (aka quantum simulators)</h3>
<div class="outline-text-3" id="text-2-3">
<p>
<div style="color:gray;">
</p>
<blockquote>
<p>
<i>Digital quantum computing</i> is based on quantum circuits and quantum gates.  On the other hand, <i>analog quantum
computing</i> (also often referred to as <i>quantum simulation</i>) attempts to perform quantum evolutions not as a
sequence of quantum gates, but through continuous manipulation of the quantum Hamiltonian.
</p>

<p>
The idea is that while exact gates are a prerequisite for fault-tolerant quantum computing, entangling gates to
date still introduce significant random noise into the computation, causing decoherence.  In comparison, some
overall quantum processes can be realized through analog quantum evolutions without giving up too much
coherence.
</p>

<p>
In the past few years, in face of the rising disappointment over the failure to exploit quantum circuit based
noisy quantum computing for industrially relevant use-cases, analog quantum computing has risen to carry the
hopes for pre-fault-tolerant commercial quantum advantage.
</p>
</blockquote>
<p>
</div>
</p>

<p>
In contrast to the previously known shift rules for quantum circuits, my method (<a href="#citeproc_bib_item_6">Theis 2022</a>) works
well with typical situation in an analog quantum computer: The part of the Hamiltonian that expresses a
parameter under consideration is active simultaneously with other, non-commuting parts.
</p>
</div>


<div id="outline-container-org819630d" class="outline-4">
<h4 id="org819630d"><span class="section-number-4">2.3.1.</span> Rydberg atom arrays and the Rydberg Blockade                                  <a id="org2827d1d"></a></h4>
<div class="outline-text-4" id="text-2-3-1">
<p>
<div style="color:gray;">
</p>
<blockquote>
<p>
The "Stable Set Problem" (also known as, "Maximum Independent Set Problem") is a classical &#x2014; and famously
hard to approximate &#x2014; combinatorial optimization problem.  Formulated on an intuitive level, when given as
input a set of objects any two of which might be <i>incompatible</i> with eat other, the Stable Set Problem asks
for finding the largest (or most highly weighted) sub-collection of pairwise compatible objects.  A great
variety of combinatorial optimization problems can be derived as Stable Set with additional constraints, or
reduced to Stable Set in a simple way.
</p>

<p>
Atom arrays, held in place (or even bussed around) with optical tweezers, offer a natural analog-quantum
formulation for Stable Set by exploiting the Rydberg blockade: If two atoms are in close proximity, there is a
heavy energy penalty for both of to be are in the excited "Rydberg" state.  It is intuitive that the
<i>incompatibility</i> relation can be modeled by identifying atoms with objects and bringing atoms representing
incompatible objects into close proximity before sending the pulses which effect the transition into the
excited state.
</p>

<p>
Next to Stable Set, atom arrays have also successfully been used for solving so-called Max-Cut (or Ising)
problems.
</p>
</blockquote>
<p>
</div>
</p>


<p>
Various publications over the last year have demonstrated the power of (reconfigurable) Rydberg atom arrays.
While the most head-turning one of them is based on quantum error correction, until a major problem &#x2014; the
continuous refill or reuse of atoms &#x2014; is solved, error corrected quantum computing on reconfigurable atom
arrays remains out of reach.  Hence, it appears that hopes for commercial quantum advantage based on Rydberg
atoms within this decade still rest on analog simulators.
</p>
</div>
</div>

<div id="outline-container-org86ac3f7" class="outline-4">
<h4 id="org86ac3f7"><span class="section-number-4">2.3.2.</span> Other analog simulators</h4>
<div class="outline-text-4" id="text-2-3-2">
<p>
Couplers between qubits in superconducting circuits can be used in an analog way, which is exploited, e.g., in
<i>digital-analog quantum computing/simulation</i>.  Derivative of the parameters within single qubits pulses can
then be taken using our method.  In superconducting qubit literature, analog quantum computing is sometimes
referred to under the term <i>sub-logical</i> control (e.g., <a href="#citeproc_bib_item_2">Babbush and Neven 2016</a>).
</p>

<p>
There have been publications using Trapped Ion quantum computers in an analog way.  However, I am
insufficiently familiar with that qubit platform to judge whether our method is applicable there, or even
whether analog quantum computing is still pursued on trapped ions at all.
</p>
</div>
</div>
</div>
</div>


<div id="outline-container-org924f9b2" class="outline-2">
<h2 id="org924f9b2"><span class="section-number-2">3.</span> <span class="todo TODO">TODO</span> How is my invention better than the other methods?</h2>
<div class="outline-text-2" id="text-3">
<p>
(<a href="#citeproc_bib_item_6">Theis 2022</a>)
</p>
</div>
</div>






<div id="outline-container-orgcab9aae" class="outline-2">
<h2 id="orgcab9aae"><span class="section-number-2">4.</span> Bibliography</h2>
<div class="outline-text-2" id="text-4">
<style>.csl-entry{text-indent: -1.5em; margin-left: 1.5em;}</style><div class="csl-bib-body">
  <div class="csl-entry"><a id="citeproc_bib_item_1"></a>Abbas, Amira, Robbie King, Hsin-Yuan Huang, William J. Huggins, Ramis Movassagh, Dar Gilboa, and Jarrod R. McClean. 2023. “On Quantum Backpropagation, Information Reuse, and Cheating Measurement Collapse.” <i>Preprint Arxiv:2305.13362</i>.</div>
  <div class="csl-entry"><a id="citeproc_bib_item_2"></a>Babbush, Ryan, and Hartmut Neven. 2016. “Training Quantum Evolutions Using Sublogical Controls.” US 10,275,717 B2; US 11,055,626 B2; US 11,562,285 B2.</div>
  <div class="csl-entry"><a id="citeproc_bib_item_3"></a>Banchi, Leonardo, and Gavin E. Crooks. 2021. “Measuring Analytic Gradients of General Quantum Evolution with the Stochastic Parameter Shift Rule.” <i>Quantum</i> 5 (January): 386. <a href="https://doi.org/10.22331/q-2021-01-25-386">https://doi.org/10.22331/q-2021-01-25-386</a>.</div>
  <div class="csl-entry"><a id="citeproc_bib_item_4"></a>Gil Vidal, Javier, and Dirk Oliver Theis. 2020. “Input Redundancy for Parameterized Quantum Circuits.” <i>Frontiers in Physics</i> 8: 297. <a href="https://doi.org/10.48550/arXiv.1901.11434">https://doi.org/10.48550/arXiv.1901.11434</a>.</div>
  <div class="csl-entry"><a id="citeproc_bib_item_5"></a>Theis, Dirk Oliver. 2021. “Optimality of Finite-Support Parameter Shift Rules for Derivatives of Variational Quantum Circuits.” <i>Preprint</i>. <a href="https://doi.org/10.48550/arXiv.2112.14669">https://doi.org/10.48550/arXiv.2112.14669</a>.</div>
  <div class="csl-entry"><a id="citeproc_bib_item_6"></a>———. 2022. “Shift Rule for Gradient Determination in Parameterised Quantum Evolutions.” US17/856,357; PCT/EP2023/068112.</div>
  <div class="csl-entry"><a id="citeproc_bib_item_7"></a>———. 2023. “``Proper’’ Shift Rules for Derivatives of Perturbed-Parametric Quantum Evolutions.” <i>Quantum</i> 7: 1052. <a href="https://doi.org/10.22331/q-2023-07-11-1052">https://doi.org/10.22331/q-2023-07-11-1052</a>.</div>
  <div class="csl-entry"><a id="citeproc_bib_item_8"></a>Wierichs, David, Josh Izaac, Cody Wang, and Cedric Yen-Yu Lin. 2021. “General Parameter-Shift Rules for Quantum Gradients.” <i>Preprint</i>. <a href="https://doi.org/10.48550/arXiv.2107.12390">https://doi.org/10.48550/arXiv.2107.12390</a>.</div>
</div>
<hr />
</div>
</div>
</div>
<div id="postamble" class="status">
<p class="date">Date: Wed Feb  7 12:34:09 CET 2024</p>
<p class="author">Author: Dirk Oliver Theis, University of Tartu, Estonia</p>
<p class="date">Created: 2024-03-06 Wed 16:19</p>
<p class="validation"><a href="https://validator.w3.org/check?uri=referer">Validate</a></p>
</div>
</body>
</html>
